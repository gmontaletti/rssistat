% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fetch_feed.R
\name{fetch_feed}
\alias{fetch_feed}
\title{Fetch and parse RSS feed}
\usage{
fetch_feed(
  url,
  since = NULL,
  until = NULL,
  timeout = 30,
  user_agent = NULL,
  verbose = FALSE
)
}
\arguments{
\item{url}{RSS feed URL (character string starting with http(s)://)}

\item{since}{Filter items on or after this date. Accepts Date, POSIXct, or
character string in "YYYY-MM-DD" format. Default NULL (no lower bound).}

\item{until}{Filter items before this date (same formats as \code{since}).
Default NULL (no upper bound).}

\item{timeout}{Request timeout in seconds. Default 30.}

\item{user_agent}{Custom HTTP User-Agent header. Default NULL (uses httr2 default).}

\item{verbose}{Print progress messages during fetching and parsing. Default FALSE.}
}
\value{
S3 object of class "rss_feed" containing:
\item{meta}{data.table with single row of feed metadata: title, link,
description, language, last_build, theme, feed_url, fetched_at}
\item{items}{data.table of feed items: title, link, description, content,
pub_date, creator, categories (list column), guid}
\item{links}{data.table of extracted links: item_title, item_link, url,
text, type, source}
}
\description{
Downloads and parses an RSS feed, extracting metadata, items, and embedded
links. Supports optional date filtering and custom HTTP configuration.
}
\examples{
\dontrun{
# Fetch ISTAT prices feed
feed <- fetch_feed("https://www.istat.it/en/tema/prices/feed")
print(feed)

# Filter by date
recent <- fetch_feed("https://www.istat.it/en/feed", since = "2025-01-01")

# Verbose output
feed <- fetch_feed("https://www.istat.it/en/feed", verbose = TRUE)
}
}
